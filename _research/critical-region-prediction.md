---
title: "Critical Region Prediction"
collection: research
permalink: /research/critical-region-prediction/
---

![Alt text](/images/ecog.png)
<h1 style="color: #6D1F8A; font-size: 24px; margin-top: 40px;">Project Summary</h1>
Current neurosurgical methods for mapping the language cortex, such as Electrical Stimulation Mapping (ESM), face significant limitations including invasiveness, time consumption, and patient cooperation challenges. Electrocorticography (ECoG) has emerged as a potential improvement by offering enhanced spatial and temporal resolution. However, its application in language mapping has been constrained by traditional analysis methods that focus narrowly on signal strength at individual electrodes. In this study, we propose a novel approach by employing transformer-based machine learning models to analyze ECoG data comprehensively. Our findings suggest that transformer architectures can advance the precision and effectiveness of language mapping techniques, potentially overcoming some of the limitations of current methods.

<h1 style="color: #6D1F8A; font-size: 24px; margin-top: 40px;">Participants</h1>
<p style="margin: 5px 0;">Yao Wang, Principal Investigator</p>
<p style="margin: 5px 0;">
  <a href="https://engineering.nyu.edu/faculty/adeen-flinker" style="color: inherit; text-decoration: underline;">Adeen Flinker</a>, Co-Principal Investigator
</p>
<p style="margin: 5px 0;">Amirhossein Khalilian-Gourtani, Postdoc</p>
<!-- <p style="margin: 5px 0;">Junbo Chen, Ph.D. student</p> -->
<p style="margin: 5px 0;">Xupeng Chen, Ph.D. student</p>
<p style="margin: 5px 0;">Antoine Ratouchniak, Visiting student</p>
<p style="margin: 5px 0;">Nika Emami, Ph.D. student</p>
<p style="margin: 5px 0;">Jinaghao Qian, Visiting student</p>

<h1 style="color: #6D1F8A; font-size: 24px; margin-top: 40px;">Sponsor</h1>
This project is funded by <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2309057&HistoricalAwards=false" style="color: #6D1F8A;">the National Science Foundation (NSF)</a>.

<!-- <h1 style="color: #6D1F8A; font-size: 24px; margin-top: 40px;">Available Code</h1> -->


<!-- <h1 style="color: #6D1F8A; font-size: 24px; margin-top: 40px;">Related Publications</h1>
<ul>
  <li>Chen, X., Wang, R., Khalilian-Gourtani, A., Yu, L., Dugan, P., Friedman, D., Doyle, W., Devinsky, O., Wang, Y. and Flinker. <a href="link-to-pnas-paper" style="color: inherit; text-decoration: none;"><strong>“A Neural Speech Decoding Framework Leveraging Deep Learning and Speech Synthesis“.</strong></a> In Nature Machine Intelligence, April 2024.</li>
  <p>Explore the available code for this project on <a href="https://github.com/flinkerlab/neural_speech_decoding" style="color: #6D1F8A;">this GitHub page</a>.</p>
  
  <li>Wang, Ran, Xupeng Chen, Amirhossein Khalilian-Gourtani, Leyao Yu, Patricia Dugan, Daniel Friedman, Werner Doyle, Orrin Devinsky, Yao Wang, and Adeen Flinker. <a href="link-to-pnas-paper" style="color: inherit; text-decoration: none;"><strong>“Distributed feedforward and feedback cortical processing supports human speech production.”</strong></a> in Proceedings of the National Academy of Sciences 120, no. 42 (2023): e2300255120.</li>
</ul> -->
