---
title: "Neural Speech Decoding"
collection: research
permalink: /research/neural-speech-decoding/
---

![Alt text](/images/ecog.png)
<h1 style="color: #6D1F8A; font-size: 24px; margin-top: 40px;">Project Summary</h1>
Decoding human speech from neural signals is essential for brain–computer
interface (BCI) technologies that aim to restore speech in populations
with neurological defcits. However, it remains a highly challenging task,
compounded by the scarce availability of neural signals with corresponding
speech, data complexity and high dimensionality. Here we present a novel
deep learning-based neural speech decoding framework that includes an
ECoG decoder that translates electrocorticographic (ECoG) signals from
the cortex into interpretable speech parameters and a novel diferentiable
speech synthesizer that maps speech parameters to spectrograms.

<h1 style="color: #6D1F8A; font-size: 24px; margin-top: 40px;">Participants</h1>
<p style="margin: 5px 0;">Yao Wang, Principal Investigator</p>
<p style="margin: 5px 0;">Adeen Flinker, Co-Principal Investigator</p>
<p style="margin: 5px 0;">Amirhossein Khalilian-Gourtani, Postdoc</p>
<p style="margin: 5px 0;">Xupeng Chen, Ph.D. student</p>
<p style="margin: 5px 0;">Nika Emami, Ph.D. student</p>
<p style="margin: 5px 0;">Chenqian Le, Ph.D. student</p>

<h1 style="color: #6D1F8A; font-size: 24px; margin-top: 40px;">Sponsor</h1>
This project is funded by <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2309057&HistoricalAwards=false" style="color: #6D1F8A;">the National Science Foundation (NSF)</a>.

<h1 style="color: #6D1F8A; font-size: 24px; margin-top: 40px;">Available Code</h1>
<p>Explore the available code for these projects on <a href="https://github.com/flinkerlab/neural_speech_decoding" style="color: #6D1F8A;">this GitHub page</a>.</p>


<h1 style="color: #6D1F8A; font-size: 24px; margin-top: 40px;">Related Publications</h1>
<ul>
  <li>Chen, X., Wang, R., Khalilian-Gourtani, A., Yu, L., Dugan, P., Friedman, D., Doyle, W., Devinsky, O., Wang, Y. and Flinker. <a href="link-to-pnas-paper" style="color: inherit; text-decoration: none;"><strong>“A Neural Speech Decoding Framework Leveraging Deep Learning and Speech Synthesis“.</strong></a> In Nature Machine Intelligence.</li>
  <li>Wang, Ran, Xupeng Chen, Amirhossein Khalilian-Gourtani, Leyao Yu, Patricia Dugan, Daniel Friedman, Werner Doyle, Orrin Devinsky, Yao Wang, and Adeen Flinker. <a href="link-to-pnas-paper" style="color: inherit; text-decoration: none;"><strong>“Distributed feedforward and feedback cortical processing supports human speech production.”</strong></a> in Proceedings of the National Academy of Sciences 120, no. 42 (2023): e2300255120.</li>
</ul>
