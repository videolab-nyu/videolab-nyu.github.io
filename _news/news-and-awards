---
title: "News and Awards"
collection: news
permalink: /news/news-and-awards/
---

<ul>
  <li>Our paper “Deep learning with diffusion MRI as in vivo microscope reveals sex-related differences in human white matter microstructure” was published in <em>Scientific Reports</em> <a href="https://www.nature.com/articles/s41598-024-60340-y">(paper link)</a>.</li>
  <li>Our paper “A neural speech decoding framework leveraging deep learning and speech synthesis” was published in <em>Nature Machine Intelligence</em> <a href="https://www.nature.com/articles/s42256-024-00824-8">(paper link)</a>. The related press release can be found <a href="https://engineering.nyu.edu/news/nyu-researchers-develop-neural-decoding-can-give-back-lost-speech">here</a>.</li>
  <li><a href="https://engineering.nyu.edu/news/nyu-tandon-cuts-rug-new-3d-video-technology" style="color: #6D1F8A; text-decoration: none;">We have a new press report</a> about our project <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2312839&HistoricalAwards=false" style="color: #6D1F8A; text-decoration: none;">“Object-Centric, View-Adaptive and Progressive Coding and Streaming of Point Cloud Video”</a> (jointly with Prof. Yong Liu and Prof. Luke DuBois).</li>
  

  <li>Our paper “Distributed feedforward and feedback cortical processing supports human speech production” was published in <em>PNAS</em> <a href="https://www.pnas.org/doi/10.1073/pnas.2300255120">(paper link)</a>. The press release about our work can be found <a href="https://engineering.nyu.edu/news/nyu-researchers-reconstruct-speech-brain-activity-illuminates-complex-neural-processes">here</a>.</li>
  

  <li>We have received an NSF award (jointly with Prof. Adeen Flinker of NYU School of Medicine) from the NSF Collaborative Research on Computational Neural Science program. The project title is <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2309057&HistoricalAwards=false" style="color: #6D1F8A; text-decoration: none;">“Novel computational approaches for neural speech prostheses and causal dynamics of language processing”</a>. Funding period: Oct. 2023 – Sept. 2026.</li>

  <li>We have received an NSF award (jointly with Prof. Yong Liu and Prof. Luke DuBois) on <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2312839&HistoricalAwards=false" style="color: #6D1F8A; text-decoration: none;">“Object-Centric, View-Adaptive and Progressive Coding and Streaming of Point Cloud Video”</a>. Funding period: Oct. 2023 – Aug. 2027.</li>

  <li>Professor Wang gave a keynote presentation on <a href="https://bpb-us-e1.wpmucdn.com/wp.nyu.edu/dist/b/10258/files/2023/10/ICML2023_CfM_keynote_final.pdf" style="color: #6D1F8A; text-decoration: none;">“Learnt compression for visual analytics on the edge at the IEEE Workshop on Coding for Machines”</a>, in conjunction with ICME 2023.</li> 

  <li>Professor Yao Wang gave a keynote talk titled <a href="https://drive.google.com/file/d/16qHDm0-b_KKVQvuZ9QNvMhkYW3nVsL5P/view?usp=sharing" style="color: #6D1F8A; text-decoration: none;">“Compression for Scene Perception and Understanding: Deep-Learning Approaches”</a> in the 2022 Picture Coding Symposium, December 7-9, 2022.</li>

  <li>We have received an NSF award (jointly with Prof. John Ross Rizzo of NYU School of Medicine, Professors Yi Fang, Maurizio Porfiri, and Sundeep Rangan from NYU Tandon) from the NSF Smart and Connected Health (SCC) program. The project title is <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1952180&HistoricalAwards=false" style="color: #6D1F8A; text-decoration: none;">“SCC-IRG Track 2: Transportation Gaps and Disability-Related Unemployment: Smarter Cities and Wearables combating Commuting Challenges for the Visually Impaired”</a>. The funding period is Oct. 2020 – Sept. 2023.</li>

  <li>We have received an NSF award (jointly with Professors Siddharth Garg and Elza Erkip) from the NSF NSF/Intel Partnership on Machine Learning for Wireless Networking Systems (MLWiNS). The project title is <a href=https://www.nsf.gov/awardsearch/showAward?AWD_ID=2003182&HistoricalAwards=false" style="color: #6D1F8A; text-decoration: none;">“MLWiNS: Resource Constrained Mobile Data Analytics Assisted by the Wireless Edge”</a>. The funding period is July 2020 – Aug. 2023.</li>

  <li>We have received an NSF award (jointly with Professor S Farokh Atashzar) from the NSF Smart and Connected Health program. The project title is <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=2031594&HistoricalAwards=false" style="color: #6D1F8A; text-decoration: none;">“RAPID: SCH: Smart Wearable COVID19 BioTracker Necklace: Remote Assessment and Monitoring of Symptoms for Early Diagnosis, Continual Monitoring, and Prediction of Adverse Event”</a>. The funding period is June 2020 – May 2021.</li>

  <li>We have received an NSF award (jointly with Prof. Adeen Flinker of NYU School of Medicine) from the NSF Collaborative Research on Computational Neural Science program. The project title is <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1912286&HistoricalAwards=false" style="color: #6D1F8A; text-decoration: none;">“Understanding Cortical Networks Related to Speech Using Deep Learning on ECOG Data”</a>. The funding period is Oct. 2019 – Sept. 2022.</li>


  <li>We received a Google Faculty Research Award for a project on <a href="https://ai.google/research/outreach/faculty-research-awards/recipients/" style="color: #6D1F8A; text-decoration: none;">Deep Learning based image and video coding</a>. Award announced Feb. 2019.</li>
  <li>Our paper “Layered Image Compression using Scalable Auto-encoder”, by Chuanmin Jia, Zhaoyi Liu, Yao Wang, Siwei Ma, Wen Gao, received the Best Student Paper Award at IEEE 2nd International Conference on Multimedia Information Processing and Retrieval (MIPR’2019). <a href="https://arxiv.org/abs/1904.00553v1">Paper link</a>.</li>
  <li>We have started a new project on automatic scene tagging for TV content. Funded by Viacom Inc./NYC Media Lab. Oct. 2018 – Jan. 2019.</li>
  <li>We have received an NSF award (jointly with Prof. Yong Liu) for <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1816500&HistoricalAwards=false" style="color: #6D1F8A; text-decoration: none;">Dynamic Predictive Streaming of 360 Degree Video</a>. The funding period is Sept. 2018 – Aug. 2021.</li>
  <li>Professor Wang gave a Keynote Presentation at Picture Coding Symposium, San Francisco, June 2018. The presentation tile is “360 Degree Video Streaming”. <a href="https://bpb-us-e1.wpmucdn.com/wp.nyu.edu/dist/b/10258/files/2018/09/v360_PCS.pdf">Presentation file</a>.</li>
  
  <li>Professor Wang’s team developed a machine learning-based method for early detection and treatment of Lymphedema, in collaboration with Professor Mei Fu from NYU College of Nursing. You can read more about this project <a href="https://engineering.nyu.edu/news/2017/01/05/nyu-tandon-researcher-uses-machine-learning-help-early-detection-treatment-lymphedem">here</a>.</li>
  
  <li>We have received a <a href="https://grants.nih.gov/grants/funding/r01.htm" style="color: #6D1F8A; text-decoration: none;">NIH R01 award</a> (jointly with Dr. Jeffrey Ketterling of Lizzi Center for Biomedical Engineering, Riverside Research, and Professor Dan Turnbull of Skirball Institute of Biomolecular Medicine, NYU School of Medicine) for a project titled <a href="http://vision.poly.edu/index.html/index.php/HomePage/vision.poly.edu/index.html/index.php/HomePage/In-uteroMouseEmbryoPhenotypingWithHigh-frequencyUltrasound" style="color: #6D1F8A; text-decoration: none;">“In utero mouse embryo phenotyping with high-frequency ultrasound,”</a> Sept. 2016 – June 2020. The focus of our team will be on developing advanced image analysis and machine learning methods for analyzing brain development in mouse embryos and characterizing defects caused by mutations based on high frequency ultrasound images of mouse embryos.</li>
  
  <li>We have received a <a href="https://grants.nih.gov/grants/funding/r01.htm" style="color: #6D1F8A; text-decoration: none;">NIH R01</a> award (jointly with Professor Mei Fu of NYU College of Nursing) for a project titled <a href="http://vision.poly.edu/index.html/index.php/HomePage/vision.poly.edu/index.html/index.php/HomePage/Kinect-enhancedLymphedemaInterventionTrainingSystem" style="color: #6D1F8A; text-decoration: none;">“Kinect-enhanced Lymphedema Intervention Training System”</a>, Sept 2016 – Aug. 2019. The project investigates the use of machine learning and video analysis for detection and intervention of Breast-Cancer related lymphedema. This project is part of the NSF/NIH joint program on Smart and Connected Health.</li>
  
  <li>We have received a <a href="https://www.nsf.gov/" style="color: #6D1F8A; text-decoration: none;">NSF award</a> (jointly with Prof. Eric Brenner of Dept. Biology in NYU College of Arts and Science) for a project titled <a href="https://wp.nyu.edu/plant_tracer/about/" style="color: #6D1F8A; text-decoration: none;">“PlantTracer: A time-lapse App for students to visualize, quantify and report novel mutants in plant motion,”</a> Sept. 2016- Aug. 2019. The project will develop an educational tool that students could use to visualize and quantify plant motion in time-lapse video, and compare motion patterns of normal vs mutant plants.</li>
  
  <li>We have received a <a href="http://grants.nih.gov/grants/funding/r21.htm" style="color: #6D1F8A; text-decoration: none;">NIH R21</a> award (jointly with Prof. Yvonne Lui, Center for Biomedical Imaging, NYU School of Medicine) for a project titled <a href="http://vision.poly.edu/index.html/index.php/HomePage/MachineLearningBasedMTBIClassificationUsingDiffusionMRI" style="color: #6D1F8A; text-decoration: none;">“Pattern Classification Using Magnetic Resonance Imaging in Traumatic Brain Injury”</a>, July 2016 – June 2018.</li>
  
  <li>The goal of this project is to develop machine learning techniques for detection and outcome prediction of Mild Traumatic Brain Injury using advanced MRI imaging features.</li>
  
  <li>We have received a gift fund from <a href="http://www.cisco.com/c/en/us/index.html" style="color: #6D1F8A; text-decoration: none;">CISCO Systems</a>, to support a project titled <a href="http://videolab.engineering.nyu.edu/cisco_vision.htm" style="color: #6D1F8A; text-decoration: none;">“Analysis and summarization of multi-view surveillance video”</a>, May 2016 – Aug. 2017.</li>
  
  <li>Professor Wang’s team is selected as one of the winners of the <a href="http://www.nycmedialab.org/verizonchallengeannouncement/" style="color: #6D1F8A; text-decoration: none;">Verizon Open Innovation Challenge Grants</a>. The project is titled as: <a href="http://videolab.engineering.nyu.edu/videosummary.php" style="color: #6D1F8A; text-decoration: none;">Witness Video Summarization: A Collective Journalistic Experience</a>, and the team members are: Yao Wang, Xin Feng, Fanyi Duanmu, Shervin Minaee. <a href="http://engineering.nyu.edu/news/2016/02/22/tandon-teams-meet-verizon-connected-futures-research-prototyping-challenge" style="color: #6D1F8A; text-decoration: none;">You can read more about this project here!</a></li>
  
  <li>MLBAM Automatic Video Annotation Challenge Grand Prize 2015: Yuanyi Xue, Yilin Song, Andy Chiang, Chenge Li <a href="http://vision.poly.edu/papers/2015/Yuanyi_MLB2015.key" style="color: #6D1F8A; text-decoration: none;">“MLB Advanced Media Automatic Video Annotation Competition”</a> <a href="https://www.youtube.com/watch?v=UKsgxVzWq28&feature=youtu.be" style="color: #6D1F8A; text-decoration: none;">“MLBAM Annotation Challenge”</a></li>
  <li>International Ultrasonic Symposium best paper award finalist 2015: Jen-wei Kuo, Yao Wang <a href="http://vision.poly.edu/papers/2015/JenWei_IUS2015.pdf" style="color: #6D1F8A; text-decoration: none;">“Automa’c Mouse Embryo Brain Ventricle Segmentation, Gesta’on Stage Estimation, and Mutant Detection from 3D 40-MHz Ultrasound Data”</a></li>

  <li>49th Asilomar Conference on Signals, Systems Conference best paper award finalist Nov 2015: Shervin Minaee, Amirali Abdolrashidi, Yao Wang <a href="http://vision.poly.edu/papers/2015/ShervinMinaee_ACSS.pdf" style="color: #6D1F8A; text-decoration: none;">“Screen Content Image Segmentation Using Sparse-Smooth Decomposition”</a></li>

  <li>4th Greater New York Area Multimedia and Vision Meeting best student poster award 2014: Jen-Wei Kuo, Xuan Zhao, and Yao Wang <a href="http://vision.poly.edu/papers/2014/JenWei_GNYMV2014.pdf" style="color: #6D1F8A; text-decoration: none;">“Nested Graph Cut for Automatic Segmentation of Nested Objects and Application to Ultrasound Images of Mouse Embryos”</a></li>

  <li>Yao Wang, Keynote speaker in the Workshop on Communication and Networking Techniques in Contemporary Video Workshop (in conjunction with INFOCOM), April 2014, Toronto, ON. Talk title: <a href="http://128.238.42.53/papers/honor/YaoWang2014INFOCOM.pdf" style="color: #6D1F8A; text-decoration: none;">“Design of low-delay video applications: Optimizing perceptual quality and error resilience”</a></li>

  <li>Yao Wang, Keynote speaker in 18th International Packet Video Workshop, Dec. 2010, Hong Kong. Talk title: <a href="http://128.238.42.53/papers/honor/YaoWang2010PV.pdf" style="color: #6D1F8A; text-decoration: none;">“Enhancing wireless video services through cooperative communications”</a></li>

  <li>IEEE Communications Society Multimedia Communication Technical Committee Best Paper Award in 2011: 
  Zhengye Liu, Yanming Shen, Keith W. Ross, Shivendra S. Panwar, and Yao Wang, 
  <a href="http://vision.poly.edu/papers/before_2010/ZhengyeLiu2009MM.pdf" style="color: #6D1F8A; text-decoration: none;">“LayerP2P: Using Layered Video Chunks in P2P Live Streaming”</a>, 
  IEEE Trans. on Multimedia (TMM), Pp. 1340-1352. November 2009.</li>
  <li>IEEE Communications Society Leonard G. Abraham Prize Paper Award in the Field of Communications Systems in 2004: 
  S. Mao, S. Lin, S. S. Panwar, Y. Wang, and E. Celebi, 
  <a href="http://vision.poly.edu/papers/before_2010/ShiwenMao2003SAC.pdf" style="color: #6D1F8A; text-decoration: none;">“Video Transport over Ad Hoc Networks: Multistream Coding with Multipath Transport”</a>, 
  IEEE Journal of Selected Areas in Communications. Special Issue on Recent Advances in Wireless Multimedia, 
  Vol. 21, No. 10, pp. 1721-1736, Dec. 2003.</li>
</ul>
